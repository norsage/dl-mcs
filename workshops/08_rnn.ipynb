{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы глубокого обучения в NLP. CharRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План на сегодня: RNN - генератор имён\n",
    "\n",
    "1. Базовая работа с текстом: токенизация, кодирование и декодирование\n",
    "2. Рекуррентные архитектуры: RNN, LSTM, GRU\n",
    "3. Обучение генерации == next token prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://download.pytorch.org/tutorial/data.zip\n",
    "# ! unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mArabic.txt\u001b[m\u001b[m     \u001b[31mEnglish.txt\u001b[m\u001b[m    \u001b[31mIrish.txt\u001b[m\u001b[m      \u001b[31mPolish.txt\u001b[m\u001b[m     \u001b[31mSpanish.txt\u001b[m\u001b[m\n",
      "\u001b[31mChinese.txt\u001b[m\u001b[m    \u001b[31mFrench.txt\u001b[m\u001b[m     \u001b[31mItalian.txt\u001b[m\u001b[m    \u001b[31mPortuguese.txt\u001b[m\u001b[m \u001b[31mVietnamese.txt\u001b[m\u001b[m\n",
      "\u001b[31mCzech.txt\u001b[m\u001b[m      \u001b[31mGerman.txt\u001b[m\u001b[m     \u001b[31mJapanese.txt\u001b[m\u001b[m   \u001b[31mRussian.txt\u001b[m\u001b[m\n",
      "\u001b[31mDutch.txt\u001b[m\u001b[m      \u001b[31mGreek.txt\u001b[m\u001b[m      \u001b[31mKorean.txt\u001b[m\u001b[m     \u001b[31mScottish.txt\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls data/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ang\n",
      "Au-Yong\n",
      "Bai\n",
      "Ban\n",
      "Bao\n"
     ]
    }
   ],
   "source": [
    "! head -n 5 data/names/Chinese.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Пишем датасет и компоновщик батчей\n",
    "\n",
    "Нам нужно:\n",
    "1. Прочитать все имена из текстовых файлов\n",
    "2. Закодировать каждое имя как последовательность целых чисел, предварительно добавив к именам символы начала и окончания (зачем?)\n",
    "3. Сохранить пары (список токенов, id языка)\n",
    "4. Сделать разбиение на train/test\n",
    "5. Реализовать сборку примеров в батчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset(Dataset):\n",
    "    # псевдоним для пары имя-язык\n",
    "    _ItemPair = tuple[list[int], int]\n",
    "\n",
    "    vocabulary: dict[str, int]\n",
    "    languages: dict[int, str]\n",
    "    names: list[_ItemPair]\n",
    "\n",
    "    def __init__(self, datadir: Path) -> None:\n",
    "        pad_token = ''\n",
    "        bos_token = '?'  # beginning of sequence\n",
    "        eos_token = '\\n'  # end of sequence\n",
    "        self.vocabulary = {pad_token: 0, bos_token: 1, eos_token: 2}\n",
    "        self.special_tokens = {0, 1, 2}\n",
    "        self.languages = {}\n",
    "        self.names = []\n",
    "        # iterate over files, update vocabulary, save name + language pairs\n",
    "        for i, language_file in enumerate(datadir.glob(\"*.txt\")):\n",
    "            self.languages[i] = language_file.stem\n",
    "            names = language_file.read_text().split('\\n')\n",
    "            for name in names:\n",
    "                for letter in name:\n",
    "                    # update vocab\n",
    "                    if letter not in self.vocabulary:\n",
    "                        self.vocabulary[letter] = len(self.vocabulary)\n",
    "                # name -> list[int]\n",
    "                encoded = self.encode(bos_token + name + eos_token)\n",
    "                self.names.append((encoded, i))\n",
    "\n",
    "        self._inverse_vocab = {value: key for key, value in self.vocabulary.items()}\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self) -> int:\n",
    "        return len(self.vocabulary)\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        return len(self.languages)\n",
    "\n",
    "    def encode(self, name: str) -> list[int]:\n",
    "        return [self.vocabulary[letter] for letter in name]\n",
    "    \n",
    "    def decode(self, encoded: list[int], remove_special_tokens: bool = False) -> str:\n",
    "        return ''.join(\n",
    "            [\n",
    "                self._inverse_vocab[idx]\n",
    "                for idx in encoded\n",
    "                if (idx not in self.special_tokens) or not remove_special_tokens\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[list[int], int]:\n",
    "        return self.names[index]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 26, 17, 24, 2] 4\n",
      "Chu Chinese\n"
     ]
    }
   ],
   "source": [
    "dataset = NamesDataset(Path(\"data/names/\"))\n",
    "tokens, label = dataset[4444]\n",
    "print(tokens, label)\n",
    "print(dataset.decode(tokens, remove_special_tokens=True), dataset.languages[label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбивка датасета на трейн и тест:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  18083\n",
      "Test size:  2009\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "train_dataset, test_dataset = random_split(dataset, lengths=[0.9, 0.1])\n",
    "print(\"Train size: \", len(train_dataset))\n",
    "print(\"Test size: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упаковка в батчи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: list[tuple[list[int], int]]) -> tuple[Tensor, Tensor]:\n",
    "    encoded, lang_ids = zip(*batch)\n",
    "    max_len = max(map(len, encoded))\n",
    "    x = torch.zeros((len(encoded), max_len), dtype=int)\n",
    "    for i, seq in enumerate(encoded):\n",
    "        x[i, :len(seq)] = torch.tensor(seq)\n",
    "    \n",
    "    return x, torch.tensor(list(lang_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens shape:  torch.Size([8, 14]) \n",
      "Labels shape:  torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "batch = [train_dataset[i] for i in range(8)]\n",
    "tokens, labels = collate_fn(batch)\n",
    "print(\"Tokens shape: \", tokens.shape, \"\\nLabels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем в загрузчик данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens shape:  torch.Size([32, 14]) \n",
      "Labels shape:  torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "tokens, labels = next(iter(train_loader))\n",
    "print(\"Tokens shape: \", tokens.shape, \"\\nLabels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Пишем простую RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с написания RNNCell - одного рекуррентного блока\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/02KvP.png\" style=\"background:white\" width=\"600\"/>\n",
    "\n",
    "<!-- <img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" style=\"background:white\" width=\"600\"/> -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    (x_{t}, h_{t-1}) -> h_{t}\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim+hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x: Tensor, h: Tensor) -> Tensor:\n",
    "        # x: B x input_dim\n",
    "        # h: B x hidden_dim\n",
    "        h = torch.cat([x, h], dim=1)\n",
    "        h = self.linear(h)\n",
    "        return F.tanh(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "input_dim = 10\n",
    "hidden_dim = 8\n",
    "cell = RNNCell(input_dim, hidden_dim)\n",
    "h = torch.zeros(1, hidden_dim)\n",
    "# расширяем до размеров батча\n",
    "h_expanded = h.expand((batch_size, -1))\n",
    "x = torch.randn(batch_size, input_dim)\n",
    "h_new = cell.forward(x, h_expanded)\n",
    "print(h_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение 1**: реализуйте более сложно устроенную LSTMCell, где теперь есть:\n",
    "1. два внутренних состояния: cell state $c_t$ и hidden state $h_t$\n",
    "2. набор гейтов для управления обновлениями состояний\n",
    "\n",
    "[blog post](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "<!-- <img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" style=\"background:white\" width=\"600\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png\" style=\"background:white\" width=\"500\"/>\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png\" style=\"background:white\" width=\"500\"/>\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png\" style=\"background:white\" width=\"500\"/>\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png\" style=\"background:white\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение 2**: реализуйте GRUCell\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png\" style=\"background:white\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем модель, состоящую из следующих блоков:\n",
    "1. `embed`: кодирует входные токены в векторы размера `hidden_dim`\n",
    "2. `rnn`: наша рекуррентная ячейка\n",
    "3. `output`: восстанавливает логиты из скрытого состояния `h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.init_h = nn.Parameter(data=torch.randn(1, hidden_dim))\n",
    "        self.rnn = RNNCell(hidden_dim, hidden_dim)\n",
    "        self.lm_head = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # x: B x T\n",
    "        # embed(x): B x T -> B x T x hidden_dim\n",
    "        B, T = x.shape\n",
    "\n",
    "        x = self.embed(x)  # B x T x hidden_dim\n",
    "        h = self.init_h.expand((B, -1)) # B x hidden_dim\n",
    "\n",
    "        logits = [] # T x B x V\n",
    "        for t in range(T):\n",
    "            xt = x[:, t, :]\n",
    "            h = self.rnn.forward(xt, h)  # B x hidden\n",
    "            y = self.lm_head(h).unsqueeze(1)  # B x 1 x hidden\n",
    "            logits.append(y)\n",
    "            # save prediction for step t + 1\n",
    "\n",
    "        # lm_head: B x T x hidden -> B x T x V\n",
    "        return torch.cat(logits, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение 3**. Добавьте в класс `RNN` возможность\n",
    "   1. Нескольких последовательных рекуррентных слоёв\n",
    "   2. Выбора другого типа рекуррентной ячейки (`GRU`, `LSTM`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 14, 90])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "model = RNN(\n",
    "    vocab_size=dataset.vocab_size,\n",
    "    hidden_dim=hidden_dim,\n",
    ")\n",
    "model.forward(tokens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Функция для генерации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схема:\n",
    "1. Подаём на вход произвольный префикс имени, можно только токен начала\n",
    "2. Проходимся моделью по префиксу, получаем логиты для следующего токена\n",
    "3. Семплируем новый токен, добавляем его к префиксу, возвращаемся к шагу 1.\n",
    "4. Критерии остановки:\n",
    "   - встретили символ окончания строки\n",
    "   - сгенерировали максимальное число новых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model: RNN, idx: Tensor, max_new_tokens: int) -> Tensor:\n",
    "    # idx: B x T\n",
    "    for t in range(max_new_tokens):\n",
    "        logits = model.forward(idx)[:, -1]  # B x T x V\n",
    "        probs = F.softmax(logits, dim=1)  # B x V\n",
    "        new_token = torch.multinomial(probs, 1)\n",
    "        idx = torch.cat([idx, new_token], dim=1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение 4**. Модифицируйте функцию `generate`, чтобы она при семплировании учитывала\n",
    "   - $k$ наиболее вероятных токенов (параметр `top_k: int`)\n",
    "   - только токены, дающие в сумме вероятность не меньше $p$ (параметр `top_p: int`)\n",
    "   - температуру для `softmax`:\n",
    "\n",
    "\n",
    "      $\\begin{aligned}\\text{softmax}(x_i, \\tau) = \\frac{\\exp(x_i / \\tau)}{\\sum_j \\exp(x_i / \\tau)} \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё понадобится функция, которая умеет декодировать выход из функции `generate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_decode(out_tokens: Tensor) -> list[str]:\n",
    "    decoded_strings = []\n",
    "    for x in out_tokens:\n",
    "        decoded_strings.append(dataset.decode(x.tolist(), remove_special_tokens=True))\n",
    "\n",
    "    return decoded_strings\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем несколько \"имён\" для проверки, начиная со $\\texttt{<BOS>}$ токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üàżDpßgŚ,ñ'ÉkŚsúöuzzçòOmDá-êW'õwYçùG1\n",
      "ąążòjñYjXłvąêÉXEöAPúçzRółbX'ßóObetUùä\n",
      "Hń1êLpgCÁ1Vòvgł,-èiŚkąuZF-yUõhłŚAyagkŻAD\n",
      "RNúzéJAQYńùiIklhÉs:xlWrÉżüéñMuVVRKVñéçPS\n"
     ]
    }
   ],
   "source": [
    "samples = generate(model, idx=torch.full(size=(4, 1), fill_value=1, dtype=int), max_new_tokens=40)\n",
    "print('\\n'.join(batch_decode(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 14, 90])\n",
      "torch.Size([32, 14])\n"
     ]
    }
   ],
   "source": [
    "logits = model.forward(tokens)\n",
    "print(logits.shape)\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4815, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(\n",
    "    logits[:, :-1].reshape(-1, dataset.vocab_size),\n",
    "    tokens[:, 1:].reshape(-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9983, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for tokens, _ in train_loader:\n",
    "        logits = model.forward(tokens)  # B x T x V\n",
    "        loss = F.cross_entropy(\n",
    "            logits[:, :-1].reshape(-1, dataset.vocab_size),\n",
    "            tokens[:, 1:].reshape(-1),\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zheson\n",
      "Vuro\n",
      "Tapi\n",
      "Archeev\n",
      "Admochiy\n",
      "Aialev\n",
      "Tutsaneno\n",
      "Jepeva\n",
      "Horondon\n",
      "Vayurov\n",
      "Dekfleng\n",
      "Zhandull\n",
      "Bamabnichkov\n",
      "Lanhnov\n",
      "Timo\n",
      "Javy\n",
      "Ribinzgi\n",
      "Babapany\n",
      "Vallin\n",
      "Zhelyur\n"
     ]
    }
   ],
   "source": [
    "samples = generate(model, idx=torch.full(size=(20, 1), fill_value=1, dtype=int), max_new_tokens=40)\n",
    "print('\\n'.join(batch_decode(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Модифицируйте вычисление ошибки, чтобы не считать её для токенов, отвечающих за паддинг. Повлияло ли это на скорость обучения модели?\n",
    "6. Добавьте в генерацию входное условие: язык для генерируемого имени\n",
    "7. Используйте `nn.LSTM` и `nn.GRU` вместо самописных моделей, сравните результаты. \n",
    "8. Реализуйте модель для классификации имён по языкам"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-mcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
